name: BigQuery Data Validation

on:
  pull_request:
    paths:
      - '.github/workflows/data-validation.yml'

jobs:
  validate:
    runs-on: ubuntu-latest

    steps:
      # 1) Check out the code
      - name: Checkout code
        uses: actions/checkout@v3

      # 2) Authenticate to GCP using your secret
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v1
        with:
          # the full JSON blob you stored in your GCP_SA_KEY secret
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      # 3) Run the count query
      - name: Run validation query
        run: |
          # run the count in CSV mode (no headers, no prompts):
          bq query \
            --nouse_legacy_sql \
            --format=csv \
            'SELECT COUNT(*) AS row_count
             FROM `neuraflow-e32ab.dns_logs.validation_test`;' \
            > validation.csv

          # show raw output for debugging
          echo "===== RAW BQ OUTPUT (CSV) ====="
          cat validation.csv
          echo "==============================="

          # skip the header, grab the first data line
          ROWS=$(tail -n +2 validation.csv | head -1)
          echo "Parsed ROWS=$ROWS"

          if [[ "$ROWS" -lt 1 ]]; then
            echo "❌ No rows found in validation_test!"
            exit 1
          fi

          echo "✅ Found $ROWS rows in validation_test."
