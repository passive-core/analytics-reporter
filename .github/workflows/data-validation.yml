name: BigQuery Data Validation

on:
  push:
    branches:
      - main
    paths:
      - '.github/workflows/data-validation.yml'
  pull_request:
    paths:
      - '.github/workflows/data-validation.yml'
  workflow_dispatch: {}

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      # 1) Check out the code
      - name: Checkout code
        uses: actions/checkout@v3
      # 2) Authenticate to GCP using your full-service-account JSON in a secret
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      # 3) Run the count query
      - name: Run validation query
        run: |
          bq --project_id=neuraflow-e32ab query \
            --nouse_legacy_sql \
            --format=csv \
            'SELECT COUNT(*) AS row_count
             FROM `neuraflow-e32ab.dns_logs.validation_test`;' \
            > validation.csv || true

      # 4) Dump raw BQ output for debugging
      - name: Dump raw BQ output
        run: |
          echo "===== RAW BQ OUTPUT (CSV + ERRORS) ====="
          cat validation.csv 2>&1 || true
          echo "======================================="

      # 5) Parse out the numeric count (skip header)
      - name: Parse count
        run: |
          ROWS=$(tail -n +2 validation.csv | head -1)
          echo "Parsed ROWS=$ROWS"

      # 6) Fail if < 1
      - name: Fail if no rows
        run: |
          if [[ -z "$ROWS" || $ROWS -lt 1 ]]; then
            echo "❌ No rows found in validation_test!"
            exit 1
          fi

      # 7) Report success
      - name: Report success
        run: |
          echo "✅ Found $ROWS rows in validation_test."
